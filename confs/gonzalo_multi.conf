general {
    base_exp_dir = ./logs/gonzalo_multi_skip_noVD_scenewiseLr10/
    recording = []
}

dataset {
    data_dirs = [
        "./datasets/Gonzalo/018/2021-05-20-17-54-26/portrait_reconstruction/",
        "./datasets/Gonzalo/019/2021-05-20-18-06-11/portrait_reconstruction/",
        "./datasets/Gonzalo/020/2021-05-27-16-17-29/portrait_reconstruction/",
        "./datasets/Gonzalo/021/2021-05-27-16-24-42/portrait_reconstruction/",
        "./datasets/Gonzalo/027/2021-05-27-17-18-14/portrait_reconstruction/",
        "./datasets/Gonzalo/060/2021-06-10-16-49-58/portrait_reconstruction/",
        "./datasets/Gonzalo/069/2021-06-24-16-25-17/portrait_reconstruction/",
        "./datasets/Gonzalo/107/2021-07-08-15-34-39/portrait_reconstruction/",
        "./datasets/Gonzalo/115/2021-07-08-17-02-02/portrait_reconstruction/",
        "./datasets/Gonzalo/119/2021-07-08-17-29-06/portrait_reconstruction/",
    ]
    images_to_pick_val = [[0, ["00586"]], [1, ["00816"]]]

    render_cameras_name = cameras_sphere.npz
    batch_size = ${train.batch_size}
}

train {
    learning_rate = 2e-4
    learning_rate_alpha = 1.0
    learning_rate_reduce_steps = [250000, 360000]
    learning_rate_reduce_factor = 0.2
    end_iter = 400000

    scenewise_layers_optimizer_extra_args {
        base_learning_rate = 2e-3
    }

    batch_size = 640
    validate_resolution_level = 2
    warm_up_end = 2000
    anneal_end = 50000 // 0
    use_white_bkgd = False

    save_freq = 10000
    val_freq = 10000
    val_mesh_freq = 10000
    report_freq = 100

    igr_weight = 0.1
    mask_weight = 0.0 // 0.1
}

model {
    scenewise_split_type = interleave_with_skips

    nerf {
        D = 8,
        d_in = 4,
        d_in_view = 3,
        W = 256,
        multires = 10,
        multires_view = 4,
        output_ch = 4,
        skips=[4],
        use_viewdirs=True
    }

    sdf_network {
        d_out = 257
        d_in = 3
        d_hidden = 256
        n_layers = 8
        skip_in = [4]
        multires = 6
        bias = 0.5
        scale = 1.0
        geometric_init = True
        weight_norm = True

        scenewise_split_type = ${model.scenewise_split_type}
    }

    variance_network {
        init_val = 0.3
    }

    rendering_network {
        d_feature = 256
        mode = no_view_dir // idr
        d_in = 6 // 9
        d_out = 3
        d_hidden = 256
        n_layers = 4
        weight_norm = True
        multires_view = 0 // 4
        squeeze_out = True

        scenewise_split_type = ${model.scenewise_split_type}
    }

    neus_renderer {
        n_samples = 64
        n_importance = 64
        n_outside = 32 // 0
        up_sample_steps = 4     // 1 for simple coarse-to-fine sampling
        perturb = 1.0
    }
}
